"""
This type stub file was generated by pyright.
"""

from keras.optimizers.optimizer_experimental import optimizer
from keras.utils import generic_utils
from tensorflow.python.util.tf_export import keras_export

"""Nadam optimizer implementation."""
@generic_utils.register_keras_serializable()
@keras_export("keras.optimizers.experimental.Nadam", v1=[])
class Nadam(optimizer.Optimizer):
    r"""Optimizer that implements the Nadam algorithm.

    Much like Adam is essentially RMSprop with momentum, Nadam is Adam with
    Nesterov momentum.

    Args:
      learning_rate: A `tf.Tensor`, floating point value, a schedule that is a
        `tf.keras.optimizers.schedules.LearningRateSchedule`, or a callable
        that takes no arguments and returns the actual value to use. The
        learning rate. Defaults to 0.001.
      beta_1: A float value or a constant float tensor, or a callable
        that takes no arguments and returns the actual value to use. The
        exponential decay rate for the 1st moment estimates. Defaults to 0.9.
      beta_2: A float value or a constant float tensor, or a callable
        that takes no arguments and returns the actual value to use. The
        exponential decay rate for the 2nd moment estimates. Defaults to 0.999.
      epsilon: A small constant for numerical stability. This epsilon is
        "epsilon hat" in the Kingma and Ba paper (in the formula just before
        Section 2.1), not the epsilon in Algorithm 1 of the paper. Defaults to
        1e-7.
      {{base_optimizer_keyword_args}}

    Reference:
      - [Dozat, 2015](http://cs229.stanford.edu/proj2015/054_report.pdf).

    """
    def __init__(self, learning_rate=..., beta_1=..., beta_2=..., epsilon=..., clipnorm=..., clipvalue=..., global_clipnorm=..., use_ema=..., ema_momentum=..., ema_overwrite_frequency=..., jit_compile=..., name=..., **kwargs) -> None:
        ...
    
    def build(self, var_list): # -> None:
        """Initialize optimizer variables.

        Nadam optimizer has 2 types of variables: momentums and velocities.

        Args:
          var_list: list of model variables to build Nadam variables on.
        """
        ...
    
    def update_step(self, gradient, variable): # -> None:
        """Update step given gradient and the associated model variable."""
        ...
    
    def get_config(self): # -> dict[str, Unknown]:
        ...
    



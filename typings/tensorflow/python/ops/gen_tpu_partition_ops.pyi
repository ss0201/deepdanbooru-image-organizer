"""
This type stub file was generated by pyright.
"""

"""Python wrappers around TensorFlow ops.

This file is MACHINE GENERATED! Do not edit.
Original C++ source file: tpu_partition_ops.cc
"""
def tpu_partitioned_input(inputs, partition_dim=..., name=...):
  r"""An op that groups a list of partitioned inputs together. This op

  Args:
    inputs: A list of at least 1 `Tensor` objects with the same type.
      A list of partitioned inputs which must have the same shape.
    partition_dim: An optional `int`. Defaults to `0`.
      An integer describles which dimension is partitioned. -1 means
      those inputs are replicated.
    name: A name for the operation (optional).

  Returns:
    A `Tensor`. Has the same type as `inputs`.
  """
  ...

TPUPartitionedInput = ...
def tpu_partitioned_input_eager_fallback(inputs, partition_dim, name, ctx):
  ...

def tpu_partitioned_output(inputs, num_splits, partition_dim=..., name=...):
  r"""An op that demultiplexes a tensor to be sharded by XLA to a list of partitioned

  outputs outside the XLA computation.

  Args:
    inputs: A `Tensor`.
      A tensor which represents the full shape of partitioned tensors.
    num_splits: An `int` that is `>= 1`.
    partition_dim: An optional `int`. Defaults to `0`.
      An integer describles which dimension is partitioned.
    name: A name for the operation (optional).

  Returns:
    A list of `num_splits` `Tensor` objects with the same type as `inputs`.
  """
  ...

TPUPartitionedOutput = ...
def tpu_partitioned_output_eager_fallback(inputs, num_splits, partition_dim, name, ctx):
  ...


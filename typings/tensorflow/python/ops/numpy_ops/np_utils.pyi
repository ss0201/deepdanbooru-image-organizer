"""
This type stub file was generated by pyright.
"""

"""Utility functions for internal use."""
def isscalar(val): # -> bool:
  """Returns whether `val` is a scalar value or scalar Tensor."""
  ...

_np_doc_form = ...
def get_np_doc_form(): # -> str:
  """Gets the form of the original numpy docstrings.

  Returns:
    See `set_np_doc_form` for the list of valid values.
  """
  ...

def set_np_doc_form(value): # -> None:
  r"""Selects the form of the original numpy docstrings.

  This function sets a global variable that controls how a tf-numpy symbol's
  docstring should refer to the original numpy docstring. If `value` is
  `'inlined'`, the numpy docstring will be verbatim copied into the tf-numpy
  docstring. Otherwise, a link to the original numpy docstring will be
  added. Which numpy version the link points to depends on `value`:
  * `'stable'`: the current stable version;
  * `'dev'`: the current development version;
  * pattern `\d+(\.\d+(\.\d+)?)?`: `value` will be treated as a version number,
    e.g. '1.16'.

  Args:
    value: the value to set the global variable to.
  """
  ...

class Link:
  def __init__(self, v) -> None:
    ...
  


class AliasOf:
  def __init__(self, v) -> None:
    ...
  


class NoLink:
  ...


def generate_link(flag, np_fun_name): # -> None:
  """Generates link from numpy function name.

  Args:
    flag: the flag to control link form. See `set_np_doc_form`.
    np_fun_name: the numpy function name.

  Returns:
    A string.
  """
  ...

_is_check_link = ...
def is_check_link(): # -> bool:
  ...

def set_check_link(value): # -> None:
  ...

_is_sig_mismatch_an_error = ...
def is_sig_mismatch_an_error(): # -> bool:
  ...

def set_is_sig_mismatch_an_error(value): # -> None:
  ...

def np_doc(np_fun_name, np_fun=..., export=..., unsupported_params=..., link=...): # -> (f: Unknown) -> Unknown:
  """Attachs numpy docstring to a function.

  Args:
    np_fun_name: name for the np_fun symbol. At least one of np_fun or
      np_fun_name shoud be set.
    np_fun: (optional) the numpy function whose docstring will be used.
    export: whether to export this symbol under module
      `tf.experimental.numpy`. Note that if `export` is `True`, `np_fun` must be
      a function directly under the `numpy` module, not under any submodule of
      `numpy` (e.g. `numpy.random`).
    unsupported_params: (optional) the list of parameters not supported
      by tf.numpy.
    link: (optional) which link to use. If `None`, a default link generated from
      `np_fun_name` will be used. If an instance of `AliasOf`, `link.value` will
      be used in place of `np_fun_name` for the link generation. If an instance
      of `Link`, `link.value` will be used as the whole link. If an instance of
      `NoLink`, no link will be added.

  Returns:
    A function decorator that attaches the docstring from `np_fun` to the
    decorated function.
  """
  ...

def np_doc_only(np_fun_name, np_fun=..., export=...): # -> (f: Unknown) -> Unknown:
  """Attachs numpy docstring to a function.

  This differs from np_doc in that it doesn't check for a match in signature.

  Args:
    np_fun_name: name for the np_fun symbol. At least one of np_fun or
      np_fun_name shoud be set.
    np_fun: (optional) the numpy function whose docstring will be used.
    export: whether to export this symbol under module
      `tf.experimental.numpy`. Note that if `export` is `True`, `np_f` must be a
      function directly under the `numpy` module, not under any submodule of
      `numpy` (e.g. `numpy.random`).

  Returns:
    A function decorator that attaches the docstring from `np_fun` to the
    decorated function.
  """
  ...

@np_doc('finfo')
def finfo(dtype): # -> Any:
  """Note that currently it just forwards to the numpy namesake, while
  tensorflow and numpy dtypes may have different properties."""
  ...

@np_doc_only('result_type')
def result_type(*arrays_and_dtypes): # -> DType:
  ...

def result_type_unary(a, dtype): # -> DType | unicode_ | Type[bytes_]:
  """Find the result type from a single input and a dtype."""
  ...

@np_doc('promote_types')
def promote_types(type1, type2):
  ...

def tf_broadcast(*args): # -> tuple[Unknown, ...] | list[Unknown | _dispatcher_for_broadcast_to | object]:
  """Broadcast tensors.

  Args:
    *args: a list of tensors whose shapes are broadcastable against each other.

  Returns:
    Tensors broadcasted to the common shape.
  """
  ...

def get_static_value(x): # -> Tensor | None:
  """A version of tf.get_static_value that returns None on float dtypes.

  It returns None on float dtypes in order to avoid breaking gradients.

  Args:
    x: a tensor.

  Returns:
    Same as `tf.get_static_value`, except that it returns None when `x` has a
    float dtype.
  """
  ...

def cond(pred, true_fn, false_fn): # -> Any | list[Unknown] | _basetuple | defaultdict[Unknown, Unknown] | ObjectProxy:
  """A version of tf.cond that tries to evaluate the condition."""
  ...

def add(a, b):
  """A version of tf.add that eagerly evaluates if possible."""
  ...

def subtract(a, b):
  """A version of tf.subtract that eagerly evaluates if possible."""
  ...

def greater(a, b):
  """A version of tf.greater that eagerly evaluates if possible."""
  ...

def greater_equal(a, b):
  """A version of tf.greater_equal that eagerly evaluates if possible."""
  ...

def less_equal(a, b):
  """A version of tf.less_equal that eagerly evaluates if possible."""
  ...

def logical_and(a, b): # -> Tensor:
  """A version of tf.logical_and that eagerly evaluates if possible."""
  ...

def logical_or(a, b): # -> Tensor:
  """A version of tf.logical_or that eagerly evaluates if possible."""
  ...

def getitem(a, slice_spec):
  """A version of __getitem__ that eagerly evaluates if possible."""
  ...

def reduce_all(input_tensor, axis=..., keepdims=...):
  """A version of tf.reduce_all that eagerly evaluates if possible."""
  ...

def reduce_any(input_tensor, axis=..., keepdims=...):
  """A version of tf.reduce_any that eagerly evaluates if possible."""
  ...

def tf_rank(t):
  ...

